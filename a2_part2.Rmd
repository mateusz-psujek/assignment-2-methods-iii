---
title: "a2_part2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
pacman::p_load(tidyverse, brms, tidybayes, conflicted, msm, readxl)

conflict_scout() #checking any possible conflicts between packages
conflict_prefer('ar', 'brms')
conflict_prefer('filter', 'dplyr')
conflict_prefer('lag', 'dplyr') #choosing the packages to prefer if conflict arises
conflict_prefer('fixed', 'stringr')
```

## Question 2
```{r}
#What is the current evidence for distinctive vocal patterns in schizophrenia? 
#       - focusing on pitch variability (PITCH_F0SD). 


# 1. Describe the data available (studies, participants). 
# 2. Fit the models
# 3. visualize and report the findings: 
    # 3.1 population level effect size;
    # 3.2 how well studies reflect it; 
    # 3.3 influential studies, 
    # 3.4 publication bias. 
# BONUS question: assess the effect of task on the estimates (model comparison with baseline model)
```

```{r}
# saving the object from part 1. In case we have to use them we won't need to rerun the whole thing
save.image('a2_part1.Rdata') 

rm(list = setdiff(ls(), lsf.str())) # clearing the whole environment except the functions
rm(effect_hist)

data_raw <- read_excel('Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx')

glimpse(data_raw)
head(data_raw)



# How the get an 'effect' variable like in the simulation? 
#   - 1. calculate cohen's d; seems to require info for both conditions, but then 5 more studies have to be removed leaving only 15. 
#   - 2. Might also work to change the model and allow it to vary by group (poll to 2 different means) like in assignment 1.


pooled_sd <- function(sd1, sd2, n1, n2){
  pooled_sd_nominator <- sqrt((n1-1)*sd1^2 + (n2-1)*sd2^2)
  pooled_sd_denominator <- sqrt(n1 + n2 - 2)
  
  return(pooled_sd_nominator / pooled_sd_denominator)
  }


cohens_d <- function(x1, x2, sd1, sd2, n1, n2){
  mean_diff <- x1 - x2

  return(mean_diff / pooled_sd(sd1, sd2, n1, n2))
  }


mean_diff_se <- function(sd1, sd2, n1, n2){
  return(pooled_sd(sd1, sd2, n1, n2) / sqrt((n1 + n2)))
  }

# I know i'll call these function just once, but I thought it will make the code easier to read



data <- data_raw %>% 
  select(1:2 | TYPE_OF_TASK | 9:22 | starts_with('PITCH_F0SD')) %>%
  filter(!(is.na(PITCH_F0SD_HC_M) | is.na(PITCH_F0SD_SZ_M))) %>% 
  rename_with(~ str_to_lower(.x) %>% 
                str_replace_all(c('_sz_sd' = '_sd_sz', '_sz_m' = '_m_sz', 
                                '_hc_sd' = '_sd_hc', '_hc_m' = '_m_hc')) %>% 
                str_replace(fixed('_hc'), '__hc') %>% 
                str_replace(fixed('_sz'), '__sz')
              ) %>%  
  #this makes pivot_longer() (later in the pipeline) easier
  add_count(studyid) %>% 
  # useful when dealing with repeated studyids (later in the pipeline)
  mutate(across(everything(), ~ str_to_lower(.x) %>% na_if('nr')),
         studyid = as.character(studyid),
         studyid = case_when(
                     n == 1                           ~ studyid,
                     n == 2 & lag(studyid) == studyid ~ paste0(studyid, 'b'),
                     TRUE                             ~ paste0(studyid, 'a')
                     ), 
         # dealing with repeated studyids
         n = NULL,
         #deleting the now useless column created by add_count(studyid)
         across(1:3, as_factor),
         across(!1:3, 
                ~ str_replace_all(.x, ',', '.') %>% 
                  str_remove_all("[^0-9.]") %>%
                  as.numeric),
          #there were weird cells like '2,63197\r\n \r\n	' that needed to be fixed before converting to numeric)
        effect = cohens_d(x1 = pitch_f0sd_m__hc, x2 = pitch_f0sd_m__sz,
                           sd1 = pitch_f0sd_sd__hc, sd2 = pitch_f0sd_sd__sz,
                           n1 = sample_size__hc, n2 = sample_size__sz),
        
        effect_sigma = mean_diff_se(sd1 = pitch_f0sd_sd__hc, sd2 = pitch_f0sd_sd__sz,
                                    n1 = sample_size__hc, n2 = sample_size__sz),
        .after = type_of_task
        ) %>% 
  pivot_longer(cols = !1:5, 
               names_to = c('.value', 'diagnosis'),
               names_sep= '__') %>% 
  mutate(diagnosis = diagnosis %>% as_factor) %>% 
  rename('n_diagnosis' = 'sample_size') %>%  
  group_by(studyid) %>% 
  mutate(sample_size = sum(n_diagnosis, na.rm = T), .after = n_diagnosis) %>% 
  ungroup
  
head(data)

rm(pooled_sd, cohens_d, mean_diff_se)
```
##### Sample size
```{r}
# Mean total sample size
data %>% filter(diagnosis == 'sz') %>%
  ggplot(aes(x = sample_size)) +
    geom_histogram(fill = 'brown', color = 'black', alpha = 0.4) +
    geom_vline(aes(xintercept = mean(sample_size, na.rm = T), color = 'mean sample size'),
                 linetype = 'dashed', size = 0.6) +
    theme_minimal() +
    labs(title = "Total sample size across the dataset",
         x = "Sample size \n (total across conditions)",
         y = "Number of studies") +
    scale_x_continuous(n.breaks = 10) +
    scale_color_manual(name = element_blank(), values = c(`mean sample size` = 'brown'))


#where the conditions balanced in terms of size?
data %>%
  ggplot(aes(x = studyid, y = n_diagnosis, fill = diagnosis)) +
    geom_bar(stat = 'identity', alpha = 0.9) +
    geom_text(aes(label = n_diagnosis), 
              size = 2.5, 
              position = position_stack(vjust = 0.3)) +
    theme_minimal() +
      labs(title = "Number of participants in each condition by study",
           x = "Study",
           y = "Number of participants") +
      scale_fill_manual(name = element_blank(), 
                        labels = c('Schizophernic condition', 'Control condition'), 
                        values = c('steelblue', 'darkolivegreen')) +
      theme(axis.text.x = element_text(angle = 90))

data %>% 
  group_by(studyid, diagnosis) %>% 
  summarise(n_diagnosis = n_diagnosis, sample_size = sample_size, pct = n_diagnosis / sample_size) %>% 
  ggplot(aes(x = studyid, fill = diagnosis)) +
    geom_bar(aes(y = pct), stat = 'identity', alpha = 0.9) +
    geom_hline(aes(yintercept = 0.5), linetype = 'dashed', size = 0.5) +
    theme_minimal() +
    labs(title = "Proportion of the two conditions in the total sample size by study",
         x = "Study",
         y = "Proportion") +
    scale_fill_manual(name = element_blank(), 
                      labels = c('Schizophrenic condition', 'Control condition'), 
                      values = c('steelblue', 'darkolivegreen')) +
    theme(axis.text.x = element_text(angle = 90))



#sum of the samples of each condition
data %>% 
  group_by(diagnosis) %>% 
  summarise(n = sum(n_diagnosis, na.rm = T)) %>% mutate(pct = n / sum(n))
```

##### Age
```{r}
# I split them in two dfs instead of making one, because I realised that makes each value repeat 2, which then makes the plot thicker

data %>% 
  select(studyid, diagnosis, age_m, age_sd) %>% 
  pivot_longer(c(age_m, age_sd),
               names_to = c(".value","age_parameter"),
               names_sep = "_") %>% 
              mutate(age_parameter = ifelse(age_parameter =="m", "Age Mean", "Age SD")) %>%                            
        ggplot(aes(x = diagnosis, y = age, fill = diagnosis))+
          geom_violin()+
          geom_boxplot(width = 0.05, fill = "white") +
          facet_wrap(~age_parameter) +
          labs(y = NULL) +
          theme_minimal()



```
##### Education
```{r}
data %>% 
  select(studyid, diagnosis, education_m, education_sd) %>% 
  pivot_longer(c(education_m, education_sd),
               names_to = c(".value","edu_parameter"),
               names_sep = "_") %>% 
  mutate(edu_parameter = ifelse(edu_parameter == "m",
                                "Years of Education Mean",
                                "Years of Education SD")) %>%
  ggplot(aes(x = diagnosis, y = education, fill = diagnosis)) +
    geom_violin() +
    geom_boxplot(width = 0.05, fill = "white") +
    facet_wrap(~edu_parameter)+
    labs(y = NULL) +
    theme_minimal()

```
### Influential studies

```{r}
data_all <- data %>% 
  distinct(studyid, effect, effect_sigma) %>% 
  rename(study = studyid)

data_all %>% 
  ggplot() +
    geom_boxplot(aes(x = effect), outlier.color = 'red') +
    ylim(-1, 1) +
    xlim(min(data_all$effect), - min(data_all$effect)) +
    xlab("Effect size (Cohen's d)") +
    theme_minimal() + 
    theme(axis.title.y = element_blank(), 
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

data_trimmed <- data_all %>% 
  filter(!(effect > quantile(effect, 0.75) + 1.5*IQR(effect) | 
         effect < quantile(effect, 0.25) - 1.5*IQR(effect)
          ))

data_trimmed %>% 
  ggplot() +
    geom_boxplot(aes(x = effect), outlier.color = 'red') +
    ylim(-1, 1) +
    xlim(min(data_all$effect), - min(data_all$effect)) +
    xlab("Effect size (Cohen's d)") +
    theme_minimal() + 
    theme(axis.title.y = element_blank(), 
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())
```

### Fitting the model
#### Defining the formula
```{r}
f <- bf(effect | se(effect_sigma) ~ 1 + (1|study))
```
#### Prior only
```{r}
get_prior(f, data_all)

priors <- c(prior(normal(0, 0.5), class = Intercept),
            prior(normal(0, 0.8), class = sd))

```

```{r}
prior_m_all <- brm(f,
                   data_all,
                   family = gaussian,
                   prior = priors,
                   sample_prior = 'only',
                   backend = 'cmdstanr',
                   cores = 3,
                   control = list(
                     adapt_delta = 0.9,
                     max_treedepth = 20))

prior_m_trimmed <- brm(f,
                       data_trimmed,
                       family = gaussian,
                       prior = priors,
                       sample_prior = 'only',
                       backend = 'cmdstanr',
                       cores = 3,
                       control = list(
                         adapt_delta = 0.9,
                         max_treedepth = 20))
```

```{r}
pp_check(prior_m_all, ndraws = 100)
pp_check(prior_m_trimmed, ndraws = 100)
```

```{r}
m_all <- brm(f, 
             data_all,
             family = gaussian,
             prior = priors,
             sample_prior = T,
             backend = 'cmdstanr',
             cores = 3,
             control = list(
               adapt_delta = 0.9,
               max_treedepth = 20))

m_trimmed <- brm(f, 
             data_trimmed,
             family = gaussian,
             prior = priors,
             sample_prior = T,
             backend = 'cmdstanr',
             cores = 3,
             control = list(
               adapt_delta = 0.9,
               max_treedepth = 20))
```
```{r}
pp_check(m_all, ndraws = 100)
pp_check(m_trimmed, ndraws = 100)

summary(m_all)
summary(m_trimmed)
```
### Convergenece checks
```{r}
models <- list(m_all, m_trimmed)
      
# launch_shinystan(f_m) # - very nice for exploring and diagnosing the model, but opens up in a new window

map(.x = models, ~ mcmc_plot(.x, type = 'trace') + 
    theme_classic() + 
    scale_color_manual(values=c("#E66101", "#998EC3", "#542788", "#F1A340")) + 
    ylab("") + 
    xlab("Iteration") + 
    labs(subtitle = 'Trace Plots'))

map(.x = models, ~ mcmc_plot(.x, type = 'rhat_hist'))
map(.x = models, ~ mcmc_plot(.x, type = 'neff'))
```
### Posterior - prior update checks
```{r}
get_variables(m_all)

map(models, pp_update_plot)
```
###### Note
The posteriors have not gotten much more confident than the priors, which might indicate a problem with the priors being to wide. However, considering the very small sample sizes (n = 15, n = 13 respectively for both models) the lack of confidence is most likely not connected to the priors.

The posterior of the SD for the model fit on all of the studies seems to be constrained by too narrow prior

### Comparing the models
```{r}

```


### Conclusions

