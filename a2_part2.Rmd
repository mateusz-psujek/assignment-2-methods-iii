---
title: "a2_part2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)
pacman::p_load(tidyverse, brms, tidybayes, conflicted, msm, readxl, metafor)

conflict_scout() #checking any possible conflicts between packages
conflict_prefer('ar', 'brms')
conflict_prefer('filter', 'dplyr')
conflict_prefer('lag', 'dplyr') #choosing the packages to prefer if conflict arises
conflict_prefer('fixed', 'stringr')
```

## Question 2
```{r}
#What is the current evidence for distinctive vocal patterns in schizophrenia? 
#       - focusing on pitch variability (PITCH_F0SD). 


# 1. Describe the data available (studies, participants). 
# 2. Fit the models
# 3. visualize and report the findings: 
    # 3.1 population level effect size;
    # 3.2 how well studies reflect it; 
    # 3.3 influential studies, 
    # 3.4 publication bias. 
# BONUS question: assess the effect of task on the estimates (model comparison with baseline model)
```

```{r}
# saving the object from part 1. In case we have to use them we won't need to rerun the whole thing
save.image('a2_part1.Rdata') 

rm(list = setdiff(ls(), lsf.str())) # clearing the whole environment except the functions
rm(effect_hist)

data_raw <- read_excel('Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx')

glimpse(data_raw)
head(data_raw)



# How the get an 'effect' variable like in the simulation? 
#   - 1. calculate cohen's d; seems to require info for both conditions, but then 5 more studies have to be removed leaving only 15. 
#   - 2. Might also work to change the model and allow it to vary by group (poll to 2 different means) like in assignment 1.

```


```{r}

cohens_d <- function(x1, x2, sd1, sd2, n1, n2){
  
  mean_diff <- x1 - x2
  pooled_sd <- sqrt((sd1^2 + sd2^2) / 2)
  
  return(mean_diff / pooled_sd)
}



cohens_d_se <- function(d, sd1, sd2, n1, n2){

  a1 <- (n1 + n2) / (n1*n2)
  a2 <- d^2 / (2*(n1 + n2 - 2))
  b <- (n1 + n2) / (n1 + n2 - 2)
  
return((a1 + a2)*b)
}
# I know i'll call these function just once, but I thought it will make the code easier to read



data <- data_raw %>% 
  select(1:2 | TYPE_OF_TASK | 9:22 | starts_with('PITCH_F0SD')) %>%
  filter(!(is.na(PITCH_F0SD_HC_M) | is.na(PITCH_F0SD_SZ_M))) %>% 
  rename_with(~ str_to_lower(.x) %>% 
                str_replace_all(c('_sz_sd' = '_sd_sz', '_sz_m' = '_m_sz', 
                                '_hc_sd' = '_sd_hc', '_hc_m' = '_m_hc')) %>% 
                str_replace(fixed('_hc'), '__hc') %>% 
                str_replace(fixed('_sz'), '__sz')
              ) %>%  
  #this makes pivot_longer() (later in the pipeline) easier
  add_count(studyid) %>% 
  # useful when dealing with repeated studyids (later in the pipeline)
  mutate(across(everything(), ~ str_to_lower(.x) %>% na_if('nr')),
         studyid = as.character(studyid),
         studyid = case_when(
                     n == 1                           ~ studyid,
                     n == 2 & lag(studyid) == studyid ~ paste0(studyid, 'b'),
                     TRUE                             ~ paste0(studyid, 'a')
                     ), 
         # dealing with repeated studyids
         n = NULL,
         #deleting the now useless column created by add_count(studyid)
         across(1:3, as_factor),
         across(!1:3, 
                ~ str_replace_all(.x, ',', '.') %>% 
                  str_remove_all("[^0-9.]") %>%
                  as.numeric),
          #there were weird cells like '2,63197\r\n \r\n	' that needed to be fixed before converting to numeric)
        effect = cohens_d(x1 = pitch_f0sd_m__hc, x2 = pitch_f0sd_m__sz,
                           sd1 = pitch_f0sd_sd__hc, sd2 = pitch_f0sd_sd__sz,
                           n1 = sample_size__hc, n2 = sample_size__sz),
        
        effect_sigma = cohens_d_se(d = effect,
                                   sd1 = pitch_f0sd_sd__hc, sd2 = pitch_f0sd_sd__sz,
                                   n1 = sample_size__hc, n2 = sample_size__sz),
        .after = type_of_task
        ) %>% 
  pivot_longer(cols = !1:5, 
               names_to = c('.value', 'diagnosis'),
               names_sep= '__') %>% 
  mutate(diagnosis = diagnosis %>% as_factor) %>% 
  rename('n_diagnosis' = 'sample_size') %>%  
  group_by(studyid) %>% 
  mutate(sample_size = sum(n_diagnosis, na.rm = T), .after = n_diagnosis) %>% 
  ungroup
  
head(data)

rm(pooled_sd, cohens_d, cohens_d_se)
```
### Describing the data
##### Sample size
```{r}
# Mean total sample size
data %>% filter(diagnosis == 'sz') %>%
  ggplot(aes(x = sample_size)) +
    geom_histogram(fill = 'brown', color = 'black', alpha = 0.4, binwidth = 10) +
    geom_vline(aes(xintercept = mean(sample_size, na.rm = T), color = 'mean sample size'),
                 linetype = 'dashed', size = 0.6) +
    theme_minimal() +
    labs(title = "Total sample size across the dataset",
         x = "Sample size \n (total across conditions)",
         y = "Number of studies") +
    scale_x_continuous(n.breaks = 14) +
    scale_color_manual(name = element_blank(), values = c(`mean sample size` = 'brown'))


#where the conditions balanced in terms of size?
data %>%
  ggplot(aes(x = studyid, y = n_diagnosis, fill = diagnosis)) +
    geom_bar(stat = 'identity', alpha = 0.9) +
    geom_text(aes(label = n_diagnosis), 
              size = 2.5, 
              position = position_stack(vjust = 0.3)) +
    theme_minimal() +
      labs(title = "Number of participants in each condition by study",
           x = "Study",
           y = "Number of participants") +
      scale_fill_manual(name = element_blank(), 
                        labels = c('Schizophernic condition', 'Control condition'), 
                        values = c('steelblue', 'darkolivegreen')) +
      theme(axis.text.x = element_text(angle = 90))

data %>% 
  group_by(studyid, diagnosis) %>% 
  summarise(n_diagnosis = n_diagnosis, sample_size = sample_size, pct = n_diagnosis / sample_size) %>% 
  ggplot(aes(x = studyid, fill = diagnosis)) +
    geom_bar(aes(y = pct), stat = 'identity', alpha = 0.9) +
    geom_hline(aes(yintercept = 0.5), linetype = 'dashed', size = 0.5) +
    theme_minimal() +
    labs(title = "Proportion of the two conditions in the total sample size by study",
         x = "Study",
         y = "Proportion") +
    scale_fill_manual(name = element_blank(), 
                      labels = c('Schizophrenic condition', 'Control condition'), 
                      values = c('steelblue', 'darkolivegreen')) +
    theme(axis.text.x = element_text(angle = 90))



#sum of the samples of each condition
data %>% 
  group_by(diagnosis) %>% 
  summarise(mean = mean(n_diagnosis) %>% round(2), 
            n = sum(n_diagnosis, na.rm = T)) %>% 
  mutate(pct = (n / sum(n)) %>% round(2))

data %>% filter(diagnosis == 'sz') %>% summarise(mean = mean(sample_size))
```

After filtering for studies that measured the pitch variability(PITCH_F0SD) for both healthy and schizophrenic conditions the number of studies got reduced to 15. Among the studies the average number of participants in total (both conditions summed) was 77.4, the mean sample size for each condition was 44.13 and 33.27 for schizophrenic and healthy conditions respectively.

Overall, the sizes of the two conditions were roughly balanced. However, some of the studies had considerably different sample sizes (e.g. study 6, 14, 47a, 47b), which might be considered problematic. The total number of participants in each condition across all of the studies was 662 (57% of all participants) and 499 (43% of all participants) for schizophrenic and healthy conditions respectively.

##### Age
```{r}
age_data <- data %>% 
  select(studyid, diagnosis, age_m, age_sd) %>% 
  pivot_longer(c(age_m, age_sd),
               names_to = c(".value","age_parameter"),
               names_sep = "_") %>% 
              mutate(age_parameter = ifelse(age_parameter =="m", "Age Mean", "Age SD"))

age_data %>% 
  ggplot(aes(x = diagnosis, y = age, fill = diagnosis))+
    geom_violin()+
    geom_boxplot(width = 0.05, fill = "white") +
    facet_wrap(~age_parameter) +
    labs(y = NULL) +
    theme_minimal()

age_data %>% 
  group_by(diagnosis, age_parameter) %>% 
  summarise(mean = mean(age, na.rm = T) %>% round(2))


#rm(age_data)
```
The two groups seems to be balanced in terms of participant's age. The means of the mean age equal to 36.44 and 34.89 for schizophrenic and healthy conditions respectively. The means of the standard deviations of age equal 8.53 and 10.35.

However, as the violin plot shows, the mean age seems to be distributed differently for the two conditions.

##### Education
```{r}
edu_data <- data %>% 
  select(studyid, diagnosis, education_m, education_sd) %>% 
  pivot_longer(c(education_m, education_sd),
               names_to = c(".value","edu_parameter"),
               names_sep = "_") %>% 
  mutate(edu_parameter = ifelse(edu_parameter == "m",
                                "Years of Education Mean",
                                "Years of Education SD"))

edu_data %>% 
  ggplot(aes(x = diagnosis, y = education, fill = diagnosis)) +
    geom_violin() +
    geom_boxplot(width = 0.05, fill = "white") +
    facet_wrap(~edu_parameter)+
    labs(y = NULL) +
    theme_minimal()

edu_data %>% 
  group_by(diagnosis, edu_parameter) %>% 
  summarise(mean = mean(education, na.rm = T) %>% round(2))

#rm(edu_data)
```
(We didn't manage to find the correct interpretation of the Education variable. We for now just assumed it refers to the number of years spend in Education)

The two groups seems to be balanced in terms of the length of their education. The means of the mean number of years spend in education equal to 13.02 and 14.02 for schizophrenic and healthy conditions respectively. The means of the standard deviations of number of years spend in education equal 2.32 and 2.26. 

However, as the violin plot shows, the mean number of years in education seems to be distributed differently for the two conditions.

##### Sex
```{r}#
#where the conditions balanced in terms of sex
data %>%
  ggplot(aes(x = studyid, y = n_diagnosis, fill = diagnosis)) +
    geom_bar(stat = 'identity', alpha = 0.9) +
    geom_text(aes(label = n_diagnosis), 
              size = 2.5, 
              position = position_stack(vjust = 0.3)) +
    theme_minimal() +
      labs(title = "Number of participants in each condition by study",
           x = "Study",
           y = "Number of participants") +
      scale_fill_manual(name = element_blank(), 
                        labels = c('Schizophernic condition', 'Control condition'), 
                        values = c('steelblue', 'darkolivegreen')) +
      theme(axis.text.x = element_text(angle = 90))

data %>% 
  group_by(studyid, diagnosis) %>% 
  summarise(n_diagnosis = n_diagnosis, sample_size = sample_size, pct = n_diagnosis / sample_size) %>% 
  ggplot(aes(x = studyid, fill = diagnosis)) +
    geom_bar(aes(y = pct), stat = 'identity', alpha = 0.9) +
    geom_hline(aes(yintercept = 0.5), linetype = 'dashed', size = 0.5) +
    theme_minimal() +
    labs(title = "Proportion of the two conditions in the total sample size by study",
         x = "Study",
         y = "Proportion") +
    scale_fill_manual(name = element_blank(), 
                      labels = c('Schizophrenic condition', 'Control condition'), 
                      values = c('steelblue', 'darkolivegreen')) +
    theme(axis.text.x = element_text(angle = 90))

```
### Influential studies

```{r}
data_all <- data %>% 
  distinct(studyid, effect, effect_sigma, sample_size) %>% 
  rename(study = studyid)

data_all %>% 
  ggplot() +
    geom_boxplot(aes(x = effect), outlier.color = 'red') +
    ylim(-1, 1) +
    xlim(min(data_all$effect), - min(data_all$effect)) +
    xlab("Effect size (Cohen's d)") +
    theme_minimal() + 
    theme(axis.title.y = element_blank(), 
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

data_trimmed <- data_all %>% 
  filter(!(effect > quantile(effect, 0.75) + 1.5*IQR(effect) | 
         effect < quantile(effect, 0.25) - 1.5*IQR(effect)
          ))

mean(data$effect)
mean(data_trimmed$effect)

```
There were two outliers present in the data in terms of effect size. Both values were much larger than what can be usually expected from effect sizes in psychology (-3.38 and 1.92), and substantially impacted the $\bar{x}$ of our small sample.

We decided to create two datasets, one with and one without the recognised outliers to see how big of an impact they would have on the regression estimates.



### Publication bias
```{r}
map(.x = list(data_all, data_trimmed), function(.x){
  
 effect_mean <- mean(.x$effect)
 effect_se <- sd(.x$effect_sigma) / sqrt(length(.x$study))
  
  uci <- effect_mean + 1.96*effect_se
  lci <-  effect_mean - 1.96*effect_se
  
  funnel_base(.x) +
    geom_segment(aes(x = uci, y = min(effect_sigma), xend = uci, yend = max(effect_sigma)), linetype = 'longdash') +
    geom_segment(aes(x = lci, y = min(effect_sigma), xend = lci, yend = max(effect_sigma)), linetype = 'longdash')
})
                   
```
There isn't a single study that would have less then 30 participants, and the plot doesn't seem to be symmetrical - much more studies appear over the right side of the triangle (bigger positive effect sizes). 
This might suggest the presence of publication bias. Smaller studies tend to have bigger standard errors which makes them more likely to be deemed not significant, and a positive effect might be expected because of previous literature.
Alternatively, the asymmetry might be explained by some methodological differences between small and big sample studies (different measuring technologies and techniques, differences in the analysis process, etc.). 
More importantly, it has to be noted that the number of studies included is very low (n = 15), and so the influence of random noise in the sample might be substantial.

### Building the models
#### Defining the formula
```{r}
f <- bf(effect | se(effect_sigma) ~ 1 + (1|study))
```
#### Prior only
```{r}
get_prior(f, data_all)

priors <- c(prior(normal(0, 0.6), class = Intercept),
            prior(normal(0, 1), class = sd))

```

```{r}
prior_m_all <- brm(f,
                   data_all,
                   family = gaussian,
                   prior = priors,
                   sample_prior = 'only',
                   backend = 'cmdstanr',
                   cores = 3,
                   control = list(
                     adapt_delta = 0.9,
                     max_treedepth = 20))

prior_m_trimmed <- brm(f,
                       data_trimmed,
                       family = gaussian,
                       prior = priors,
                       sample_prior = 'only',
                       backend = 'cmdstanr',
                       cores = 3,
                       control = list(
                         adapt_delta = 0.9,
                         max_treedepth = 20))
```

```{r}
pp_check(prior_m_all, ndraws = 100)
pp_check(prior_m_trimmed, ndraws = 100)
```
#### Fitting the models
```{r}
m_all <- brm(f, 
             data_all,
             family = gaussian,
             prior = priors,
             sample_prior = T,
             backend = 'cmdstanr',
             cores = 3,
             control = list(
               adapt_delta = 0.9,
               max_treedepth = 20))

m_trimmed <- brm(f, 
             data_trimmed,
             family = gaussian,
             prior = priors,
             sample_prior = T,
             backend = 'cmdstanr',
             cores = 3,
             control = list(
               adapt_delta = 0.9,
               max_treedepth = 20))
```
```{r}
pp_check(m_all, ndraws = 100)
pp_check(m_trimmed, ndraws = 100)

summary(m_all)
summary(m_trimmed)
```
#### Convergenece checks
```{r}
models <- list(m_all, m_trimmed)
      
# launch_shinystan(f_m) # - very nice for exploring and diagnosing the model, but opens up in a new window

map(.x = models, ~ mcmc_plot(.x, type = 'trace') + 
    theme_classic() + 
    scale_color_manual(values=c("#E66101", "#998EC3", "#542788", "#F1A340")) + 
    ylab("") + 
    xlab("Iteration") + 
    labs(subtitle = 'Trace Plots'))

map(.x = models, ~ mcmc_plot(.x, type = 'rhat_hist'))
map(.x = models, ~ mcmc_plot(.x, type = 'neff'))
```
#### Posterior - prior update checks
```{r}
map(models, pp_update_plot)
```
### Comparing the models
#### Population effects
```{r}
bind_rows(data.frame(fixef(m_all)) %>% mutate(model = "m_all"),
          data.frame(fixef(m_trimmed)) %>% mutate(model = "m_trimmed")) %>% 
  ggplot(aes(x = Estimate, y = model, xmin = Q2.5, xmax = Q97.5))+
    geom_pointrange()+
    xlab("population level effect size")+
    ggtitle("95% confidence interval of the estimated population level effect size")+
    ylab(NULL)+
    theme_minimal()


```
#### Individual effects 

### Conclusions

